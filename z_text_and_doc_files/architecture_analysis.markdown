## File Interoperability & Architecture

Here's how all your files work together in a layered architecture:

### **ğŸ—ï¸ Architecture Layers**

## 1. Core Infrastructure Layer
**Files:** `config.py`, `setup_chroma.py`

- `config.py` â†’ Provides configuration to ALL files (API keys, paths, model names)[1]
- `setup_chroma.py` â†’ Creates ChromaDB collections and embedding functions[2]
- **Relationship:** Setup runs once to initialize the database structure

## 2. Data Processing Layer
**Files:** `document_processor.py`, `index_icici_docs.py`

**Flow:**
```
.txt files â†’ index_icici_docs.py â†’ setup_chroma.py â†’ ChromaDB
```

- `index_icici_docs.py` reads your corpus files[3]
- Uses `setup_chroma.py` to connect to ChromaDB[2]
- Chunks documents and stores embeddings[4]
- **Must run before agents can answer questions**

## 3. Retrieval Layer
**File:** `retriever.py`

- Connects to ChromaDB collections[5]
- Provides semantic search functionality
- Used by: `knowledge_agent.py`, `validate.py`

## 4. Utility Layer
**Files:** `cache_manager.py`, `memory_manager.py`, `observability.py`, `feedback_system.py`

These are **independent supporting systems** used by `supervisor_agent.py`:

- **cache_manager.py** â†’ Prevents duplicate LLM calls[6]
- **memory_manager.py** â†’ Maintains conversation context[7]
- **observability.py** â†’ Logs performance metrics[8]
- **feedback_system.py** â†’ Collects user ratings[9]

## 5. Agent Layer
**Files:** `knowledge_agent.py`, `marketing_agent.py`, `supervisor_agent.py`

**Knowledge Agent Flow:**
```
Query â†’ retriever.py â†’ ChromaDB â†’ LLM (Groq) â†’ Answer
```


**Marketing Agent Flow:**
```
Campaign params â†’ LLM (Groq) â†’ Generated content
```


**Supervisor Agent (Main Orchestrator):**
```
User Query 
  â†“
Check cache_manager (hit? return cached)
  â†“
Classify query (knowledge vs marketing)
  â†“
Route to â†’ knowledge_agent OR marketing_agent
  â†“
Save to cache_manager
  â†“
Log to observability
  â†“
Store in memory_manager
  â†“
Return response
```


## 6. Testing Layer
**Files:** All `test_*.py` and `validate.py`

- `validate.py` â†’ Tests retriever directly[10]
- `test_rag.py` â†’ Tests knowledge_agent[11]
- `test_multi_agent.py` â†’ Tests supervisor routing[12]
- `test_memory_cache.py` â†’ Tests utility systems[13]
- `test_observability.py` â†’ Tests monitoring[14]

### **ğŸ”„ Complete Data Flow**

**Initial Setup (Run Once):**
```
1. setup_chroma.py â†’ Creates DB structure
2. index_icici_docs.py â†’ Loads your documents into ChromaDB
3. validate.py â†’ Verify indexing worked
```

**Runtime Flow (Every Query):**
```
User Query
    â†“
supervisor_agent.py
    â†“
[Check Cache] cache_manager.py â”€â”€â”€ Cache Hit? â†’ Return
    â†“ (Cache Miss)
[Classify Query] â†’ Knowledge or Marketing?
    â†“                           â†“
knowledge_agent.py          marketing_agent.py
    â†“                           â†“
retriever.py                Groq LLM
    â†“
ChromaDB
    â†“
Groq LLM (combines docs + query)
    â†“
[Response Generated]
    â†“
cache_manager.py (save for next time)
    â†“
observability.py (log metrics)
    â†“
memory_manager.py (save to session)
    â†“
Return to user
    â†“
[Optional] feedback_system.py (collect rating)  
```

### **ğŸ“¦ Dependency Graph**

```
config.py â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â†“                       â†“
setup_chroma.py â†’ index_icici_docs.py â†’ ChromaDB
    â†“
retriever.py
    â†“
knowledge_agent.py â”€â”€â”€â”€â”
                       â†“
marketing_agent.py â”€â”€â”€â”€â†’ supervisor_agent.py â†â”€â”€ cache_manager.py
                              â†‘                â†â”€â”€ memory_manager.py
                              â†‘                â†â”€â”€ observability.py
                              â†‘                â†â”€â”€ feedback_system.py
                              â†“
                         [All test files]
```

### **ğŸ¯ Key Interconnections**

**supervisor_agent.py is the central hub** that connects:
- Both agents (knowledge + marketing)[15]
- All 4 utility systems (cache, memory, logs, feedback)
- Groq LLM for classification
- Returns unified responses

**knowledge_agent.py is a RAG pipeline**:
1. Uses `retriever.py` for semantic search[16]
2. Formats retrieved docs as context
3. Sends to Groq LLM for generation

**All utility systems are independent**:
- They don't talk to each other
- Only `supervisor_agent.py` coordinates them
- Can be enabled/disabled with flags

The architecture follows a **clean separation of concerns** where each file has one specific job, making it easy to debug, test, and extend!